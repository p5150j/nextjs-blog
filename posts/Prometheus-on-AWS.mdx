---
title: Prometheus Deep Dive
description: "Prometheus open-source monitoring and alerting tool. We will discuss how to install, configure, and run the various components of the Prometheus ecosystem."
date: Nov 1 2022
---

### Lets get this setup.

Lets assume you have an AWS VM, for this Ill be using a basic Ubuntu t2.micro on AWS with `Port range inbound [9090, 443, 22, 80]`.

ssh into your vm 

````bash
ssh -i "<your>.pem" ubuntu@ec2-<your-ip>.compute-1.amazonaws.com
````

We will want to add a user and a group that will be used by Prometheus.

```bash
sudo useradd -M -r -s /bin/false prometheus
```

Now lets make some folders for configs and prometheus data
```bash
sudo mkdir /etc/prometheus 
sudo mkdir /var/lib/prometheus
```
Now let's get/download the binaries and un-tar/extract em'

 ```bash
 wget https://github.com/prometheus/prometheus/releases/download/v2.16.0/prometheus-2.16.0.linux-amd64.tar.gz
 tar xzf prometheus-2.16.0.linux-amd64.tar.gz 
 ```
### Lets do some organization.

 Now that we have them locally lets move/copy some stuff around and get them living in the correct directories we created before
 ```bash
sudo cp prometheus-2.16.0.linux-amd64/{prometheus,promtool} /usr/local/bin/
 ```

 add our Prometheus as the owner of the files in the directories
 ```bash
 sudo chown prometheus:prometheus /usr/local/bin/{prometheus,promtool}
 ```

 More moving files around to the correct locations
 ```bash
 sudo cp -r prometheus-2.16.0.linux-amd64/{consoles,console_libraries} /etc/prometheus/
 ```

 Now lets move our config yml (we will get into editing the config later)
 ```bash
 sudo cp prometheus-2.16.0.linux-amd64/prometheus.yml /etc/prometheus/prometheus.yml
 ```

 again add our Prometheus user as the owner respectivly to each directory
 ```bash
 sudo chown -R prometheus:prometheus /etc/prometheus
 sudo chown prometheus:prometheus /var/lib/prometheus
 ```

 ### Lets give this a test!!
Just run prometheus and point to the config

 ```bash
prometheus --config.file=/etc/prometheus/prometheus.yml
 ```
 and we should see it up and running
 ```bash
level=info ts=2022-11-11T16:17:13.183Z caller=main.go:676 fs_type=EXT4_SUPER_MAGIC
level=info ts=2022-11-11T16:17:13.183Z caller=main.go:677 msg="TSDB started"
level=info ts=2022-11-11T16:17:13.183Z caller=main.go:747 msg="Loading configuration file" filename=/etc/prometheus/prometheus.yml
level=info ts=2022-11-11T16:17:13.186Z caller=main.go:775 msg="Completed loading of configuration file" filename=/etc/prometheus/prometheus.yml
level=info ts=2022-11-11T16:17:13.187Z caller=main.go:630 msg="Server is ready to receive web requests."
 ```


 Cool story bro, but this doesnt cover a production usecase nor give me an idea of how to even use it. Lets start by making this a system service that just runs in the background and boots up if there is ever a restart.
 
 ### Systemd that as a boot service.

 Create a systemd unit file for Prometheus:
 ```bash
 sudo nano /etc/systemd/system/prometheus.service
 ```

 ```bash
[Unit]
Description=Prometheus Time Series Collection and Processing Server
Wants=network-online.target
After=network-online.target
[Service]
User=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
 --config.file /etc/prometheus/prometheus.yml \
 --storage.tsdb.path /var/lib/prometheus/ \
 --web.console.templates=/etc/prometheus/consoles \
 --web.console.libraries=/etc/prometheus/console_libraries
[Install]
WantedBy=multi-user.target
 ```


 Now lets start it in the background
 ```bash
 sudo systemctl daemon-reload
 sudo systemctl start prometheus
 sudo systemctl enable prometheus
 ```

 and you should get some outpout like this
 ```bash
 Created symlink /etc/systemd/system/multi-user.target.wants/prometheus.service → /etc/systemd/system/prometheus.service.
 ```

 ### Test it out.

 Lets make sure its running
 ```bash
 curl localhost:9090
 ```

 You can also hit your public IP and use the GUI on `port 9090`
 
 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/prom.png "image Title")

### Edit your config
 Lets start playing around with the config a bit now 
 ```shell
 sudo nano /etc/prometheus/prometheus.yml 
 ```
and edit the `scrape_interval:` to something like `10s`
```shell
scrape_interval: 10s
```

and then we need to reboot prometheus
```shell
sudo systemctl start prometheus
```

or you can just do it without a full reboot
```shell
sudo killall -HUP prometheus
```

Now lets just verify the change has taken effect

```shell
curl localhost:9090/api/v1/status/config
```

## Nuff talk, can I haz data?

### Exporters
A prometheus exporter is any application that exposes metric data in a format that can be collected (or scraped) by prometheus server.
For example, Node exporter runs on an a *NIX machine and collects a varity of system metrics, It then exposes them to prometheus.
Once we have our exporter setup we will need to point our scrape config 

--------

For this we will need a VM that we want to export data form.
I have again, just spun up a simple Ubuntu t2.micro on AWS  with `Port range inbound [9100, 9090, 443, 22, 80] and outbound [9100]`.

ssh into your vm 

````bash
ssh -i "<your>.pem" ubuntu@ec2-<your-ip>.compute-1.amazonaws.com
````
Create a user for Node Exporter:
```bash
sudo useradd -M -r -s /bin/false node_exporter
```

Download and extract the Node Exporter binary:
```bash
wget https://github.com/prometheus/node_exporter/releases/download/
v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gz
```

```bash
tar xvfz node_exporter-0.18.1.linux-amd64.tar.gz
``` 
Copy the Node Exporter binary to the appropriate location and set ownership:
```bash
sudo cp node_exporter-0.18.1.linux-amd64/node_exporter /usr/local/bin/
```
```bash
sudo chown node_exporter:node_exporter /usr/local/bin/node_exporter
```

Create a systemd unit file for Node Exporter:
```bash
sudo nano /etc/systemd/system/node_exporter.service
```
Define the Node Exporter service in the unit file:
```bash
[Unit]
Description=Prometheus Node Exporter
Wants=network-online.target
After=network-online.target
[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter
[Install]
WantedBy=multi-user.target
```

Start and enable the node_exporter service:
```bash
sudo systemctl daemon-reload
sudo systemctl start node_exporter
sudo systemctl enable node_exporter
```

and again you should see your output:
```bash
Created symlink /etc/systemd/system/multi-user.target.wants/node_exporter.service → /etc/systemd/system/node_exporter.service.
```
You can retrieve the metrics served by Node Exporter like so:
```bash
curl localhost:9100/metrics
```
and you should see your metrics output
```bash
.................
......................
# TYPE node_vmstat_pgmajfault untyped
node_vmstat_pgmajfault 1228
# HELP node_vmstat_pgpgin /proc/vmstat information field pgpgin.
# TYPE node_vmstat_pgpgin untyped
node_vmstat_pgpgin 246511
# HELP node_vmstat_pgpgout /proc/vmstat information field pgpgout.
# TYPE node_vmstat_pgpgout untyped
node_vmstat_pgpgout 302657
# HELP node_vmstat_pswpin /proc/vmstat information field pswpin.
# TYPE node_vmstat_pswpin untyped
node_vmstat_pswpin 0
# HELP node_vmstat_pswpout /proc/vmstat information field pswpout.
# TYPE node_vmstat_pswpout untyped
node_vmstat_pswpout 0
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 0
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
....................................
.......................................................
promhttp_metric_handler_requests_total{code="200"} 0
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
```

### Configure Prometheus to Scrape Metrics


Lets go back to our Prometheus server VM now so we can scrape the metrics. We will edit the prometheus.yml and add our exporter to that file
```bash
 sudo nano /etc/prometheus/prometheus.yml
 ```
Now lets make sure its pointed to our exporter on the other server
```bash
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']

# adding the new one here
  - job_name: 'Prom export box'
    static_configs:
    - targets: ['<Your-Private-IP>:9100']
```

Then make sure you bounce the config to read the new version 
```bash
sudo killall -HUP prometheus
```

You can also hit your public IP and use the GUI on `port 9090` and query the `up` metric to validate you have data coming back.

 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/promup.png "image Title")

and you can see we have connected to the remote exporter
```bash
up{instance="<Your-Private-IP>:9100",job="Prom export box"}

#(value = 1)
```

Lets try something more useful like query the `node_filesystem_avail_bytes` to see what storage is avalible

and it should output directories and avalible space

 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/node_filesystem_avail_bytes.png "image Title")

```bash
node_filesystem_avail_bytes{device="/dev/root",fstype="ext4",instance="...:9100",job="Prom export box",mountpoint="/"}	5674483712
node_filesystem_avail_bytes{device="/dev/xvda15",fstype="vfat",instance="...:9100",job="Prom export box",mountpoint="/boot/efi"}	103965696
node_filesystem_avail_bytes{device="none",fstype="ramfs",instance="...:9100",job="Prom export box",mountpoint="/run/credentials/systemd-sysusers.service"}	0
node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",instance="...:9100",job="Prom export box",mountpoint="/run"}	201748480
node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",instance="...:9100",job="Prom export box",mountpoint="/run/lock"}	5242880
node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",instance="...:9100",job="Prom export box",mountpoint="/run/snapd/ns"}	201748480
node_filesystem_avail_bytes{device="tmpfs",fstype="tmpfs",instance="...:9100",job="Prom export box",mountpoint="/run/user/1000"}	101306368
```

Thats nice and all, but what about something like time-series data? You know, like somehting I can use for actaully using these mertics for more than just a static data pull.

### Time-series Data

#### Metric names and Labels
One of things I found was that just pulling a metric name via a query will get back more data than I ahd assumed.
As an example if I query `node_cpu_seconds_total` I end up getting back all CPU states, on each CPU, and n* for each VM I have an exporter running on

 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/node_cpu_seconds_total.png "image Title")

```bash
node_cpu_seconds_total{cpu="0",.......mode="idle"}	610552.47
node_cpu_seconds_total{cpu="0",.......mode="iowait"}	96.28
node_cpu_seconds_total{cpu="0",.......mode="irq"}	0
node_cpu_seconds_total{cpu="0",.......mode="nice"}	109.83
.......
.................
```

Each of these are labels, and what prometheus calls dimensional data models. As you can see we have `cpu, instance, job, mode` and each have their own value that further dimensionalize the data.
With lables in mind, lets try and filter that list down even further..


```bash
node_cpu_seconds_total{mode="idle"}
```

 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/node_cpu_seconds_total{mode="idle"}.png 'image Title')

## Metric types 
This is when you start to see the power of Prometheus as we can chain our lables with a time durration.
#### Counters 
A counter is a single number that can only increase or be reset to zero.

<em>eg: </em>

- Number of HTTP requests served by the application
- Number of records processed
- Number of application restarts
- Number of errors
- etc...

Lets try something with time durration 
```bash
node_cpu_seconds_total{mode="idle"}[5m]
```
 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/counter-5m.png "image Title")


#### Gauge

A gauge is a simgle number that can increase and decrease over time.

<em>eg: </em>

- Number of concurent HTTP requests 
- CPU/GPU usage
- Memeory usage
- Current active threads
- etc...

and again... lets try something we know will + and - over time
```bash
node_memory_MemAvailable_bytes[5m]
```
 ![alt text](https://arusimagesforsite.s3.us-west-2.amazonaws.com/gauge-1.png "image Title")

 #### Histogram

 A Histogram counts the number of observations/events that fall into a set of configurable buckets, each with its own separate time series. A Histogram will use lables to differentiate between buckets. The below example shows the number of HTTP requests whose durration falls into each bucket.
 For this examople lets have prometheus monitor itself (since its the only server we have http traffic on spun up on our VM)
 ```bash
 prometheus_http_request_duration_seconds_bucket{le="0.1"}
 prometheus_http_request_duration_seconds_bucket{le="0.3"}
 prometheus_http_request_duration_seconds_bucket{le="1.0"}
 ```
take this a step further and onyl grab requests from the /metrics endpoint that resolved in less that 0.1 seconds
```bash
prometheus_http_request_duration_seconds_bucket{handler="/metrics", le="0.1"}
```


 Histograms also include metric names to expose the `_sum` of all values and the total `_count` of them
 ```bash
prometheus_http_request_duration_seconds_count{handler="/metrics"}
prometheus_http_request_duration_seconds_sum{handler="/metrics"}
 ```
 This lets us get the full sum and count.

  #### Summary

  A Summary is similar to a Histogram, but it exposes metrics in the form of quantiles instead of buckets. While buckets divide values based on boundries, quantiles divide values based on percentiles into which they fall.
  This value shows the number of HTTP requests whose durration falls within the 95th % of all requests or 5% on longest requests. These arent used as much, but worth calling out as we might use them later.

Lets check garbage collection golang metrics 
```bash
go_gc_duration_seconds{quantile="0.25"}
```

## Querying (PromQL)
You can use Prometheus queries (PromQL) in a varity of ways to obtain and work with your data.
- Expression browser (like youve seen so far)
- Prometheus API 
- Visulation tools like Grafana 

### Label Matching 
Youve seen simple label's `node_cpu_seconds_total{cpu="0"}` , but we can extend this even further with label matching
- =: Equals
- !=: Does not equal
- =~: Regex matching
- !~: Does not regex match 
---
```bash
node_cpu_seconds_total{cpu="0"}
node_cpu_seconds_total{cpu=!"0"}
node_cpu_seconds_total{cpu=~"1*"}
node_cpu_seconds_total{cpu!~"1*"}
```

### Offset modifier 
You can use this to select data from the past and chain all our other selctors on top of it.

```bash
node_cpu_seconds_total offset 1h
node_cpu_seconds_total[5m] offset 1h
```

## Query Operators 

### Arithmetic Bianry Operators

The following operators preform basic arithmetic on numeric values
- +: add
- -: subtract
- *: multiply
- /: divide
- %: modulo
- ^: exponent